Model Summary: SpeechRecognitionModel(
  (conv1): Conv2dBlock(
    (conv): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (layer_norm): Sequential(
      (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
      (1): ReLU()
      (2): Dropout(p=0.1, inplace=False)
    )
  )
  (conv2): Conv2dBlock(
    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (layer_norm): Sequential(
      (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
      (1): ReLU()
      (2): Dropout(p=0.1, inplace=False)
    )
  )
  (conv3): Conv2dBlock(
    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (layer_norm): Sequential(
      (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
      (1): ReLU()
      (2): Dropout(p=0.1, inplace=False)
    )
  )
  (dense): Sequential(
    (0): Linear(in_features=2560, out_features=1280, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=1280, out_features=512, bias=True)
  )
  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (gru): GRU(512, 256, batch_first=True, bidirectional=True)
  (fc): Linear(in_features=512, out_features=29, bias=True)
)
Model Parameters: 5152381
Features Shape: torch.Size([32, 501, 80])
Labels Shape: torch.Size([32, 89])
Features Length: tensor([501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501])
Shape: torch.Size([32])
Labels Length: tensor([73, 62, 65, 74, 48, 69, 71, 63, 50, 63, 56, 58, 48, 48, 61, 56, 42, 42,
        50, 62, 47, 48, 60, 40, 89, 77, 58, 50, 38, 42, 42, 53])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Batch Loss: 23.8940
Batch Loss: 23.8940
Target: [3, 5, 12, 4, 9, 4, 3, 15, 8, 17, 4, 3, 7, 10, 3, 5, 12, 11, 4, 4, 3, 18, 13, 6, 24, 8, 16, 11, 9, 3, 4, 27, 8, 5, 7, 15, 3, 15, 12, 4, 11, 11, 22, 3, 23, 4, 11, 11, 22, 3, 23, 13, 6, 9, 5, 3, 6, 10, 14, 3, 19, 6, 11, 6, 14, 7, 9, 4, 3, 17, 7, 10, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [23, 23, 15, 13, 24, 24, 24, 13, 13, 0, 23, 24, 24, 24, 0, 24, 24, 24, 0, 0, 0, 23, 0, 5, 23, 23, 23, 23, 5, 15, 15, 24, 6, 24, 6, 13, 13, 0, 0, 0, 0, 24, 13, 15, 13, 25, 0, 0, 0, 0, 24, 15, 24, 23, 13, 13, 15, 15, 5, 13, 6, 0, 0, 0, 5, 5, 5, 24, 13, 24, 15, 24, 24, 24, 0, 0, 0, 13, 0, 0, 13, 24, 13, 13, 15, 13, 24, 24, 15, 15, 24, 24, 15, 15, 15, 5, 5, 7, 6, 6, 24, 0, 25, 6, 6, 25, 13, 13, 6, 0, 15, 0, 6, 24, 6, 0, 6, 13, 0, 6, 6, 6, 15, 6, 24, 6, 6, 5, 5, 23, 24, 0, 24, 15, 24, 0, 0, 0, 0, 13, 5, 5, 6, 6, 24, 15, 15, 24, 0, 0, 0, 24, 24, 13, 13, 23, 23, 15, 13, 23, 13, 6, 13, 7, 15, 15, 15, 0, 0, 0, 0, 7, 13, 13, 15, 15, 15, 0, 0, 24, 24, 0, 0, 15, 15, 0, 24, 24, 6, 6, 13, 24, 24, 0, 0, 24, 6, 0, 6, 13, 13, 24, 15, 24, 24, 24, 24, 6, 24, 24, 13, 0, 15, 13, 24, 13, 5, 6, 15, 0, 23, 23, 23, 23, 15, 15, 15, 10, 24, 13, 13, 0, 13, 0, 0, 6, 23, 13, 5, 15, 0, 15, 15, 15, 15, 5, 0, 0, 24, 0, 6, 24, 13, 6, 6, 15, 13, 13, 13, 24, 0, 0, 0, 24, 24, 5, 5, 24, 24, 24, 0, 0, 0, 15, 0, 0, 0, 24, 24, 5, 24, 13, 13, 6, 5, 2, 13, 24, 6, 13, 13, 13, 5, 6, 6, 6, 23, 23, 23, 13, 0, 24, 0, 5, 0, 5, 15, 13, 13, 13, 24, 13, 24, 23, 6, 15, 15, 13, 13, 6, 15, 15, 15, 24, 24, 24, 24, 15, 15, 0, 13, 24, 24, 24, 6, 13, 7, 24, 15, 0, 13, 13, 13, 13, 13, 13, 13, 23, 15, 0, 0, 0, 15, 15, 24, 24, 24, 0, 6, 0, 6, 5, 5, 5, 24, 0, 0, 0, 0, 23, 0, 5, 0, 0, 0, 0, 0, 0, 15, 13, 24, 13, 24, 23, 24, 15, 24, 0, 23, 13, 23, 6, 0, 15, 13, 13, 24, 13, 0, 13, 0, 15, 15, 24, 23, 15, 0, 5, 5, 5, 0, 15, 15, 0, 15, 24, 24, 24, 24, 15, 15, 15, 0, 15, 6, 0, 0, 0, 6, 0, 0, 0, 15, 15, 5, 13, 13, 13, 13, 0, 0, 0, 6, 0, 5, 0, 0, 15, 15, 15, 15, 23, 0, 15, 15, 23, 6, 15, 23, 13, 13, 10, 13, 23, 13, 15, 8, 15, 25, 24, 13, 23, 13, 13, 23, 23, 23, 23, 24, 6, 15, 15, 24, 6, 6, 24, 24, 15, 24, 24, 13, 13, 24, 24, 0, 24, 6, 15, 15, 6, 13]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 2 / 13]
Batch Loss: 3.4762
Batch Loss: 3.4762
Target: [3, 5, 12, 4, 22, 3, 7, 9, 8, 13, 6, 5, 4, 3, 5, 12, 4, 17, 9, 4, 13, 24, 4, 9, 3, 9, 8, 15, 7, 6, 13, 13, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 3 / 13]
Model Summary: SpeechRecognitionModel(
  (conv1): Conv2dBlock(
    (conv): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (layer_norm): Sequential(
      (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
      (1): ReLU()
      (2): Dropout(p=0.1, inplace=False)
    )
  )
  (conv2): Conv2dBlock(
    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (layer_norm): Sequential(
      (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
      (1): ReLU()
      (2): Dropout(p=0.1, inplace=False)
    )
  )
  (conv3): Conv2dBlock(
    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (layer_norm): Sequential(
      (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
      (1): ReLU()
      (2): Dropout(p=0.1, inplace=False)
    )
  )
  (dense): Sequential(
    (0): Linear(in_features=2560, out_features=1280, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=1280, out_features=512, bias=True)
  )
  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (gru): GRU(512, 256, batch_first=True, bidirectional=True)
  (fc): Linear(in_features=512, out_features=29, bias=True)
)
Model Parameters: 5152381
Features Shape: torch.Size([32, 501, 80])
Labels Shape: torch.Size([32, 88])
Features Length: tensor([501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501])
Shape: torch.Size([32])
Labels Length: tensor([49, 54, 44, 50, 50, 62, 42, 54, 55, 61, 67, 52, 49, 56, 56, 62, 68, 64,
        54, 54, 63, 51, 50, 74, 64, 81, 54, 81, 53, 54, 88, 62])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Batch Loss: 24.0289
Batch Loss: 24.0289
Target: [3, 5, 12, 4, 3, 24, 7, 13, 13, 6, 20, 4, 3, 7, 9, 3, 13, 8, 15, 6, 5, 4, 14, 3, 21, 7, 5, 12, 7, 10, 3, 5, 12, 4, 3, 5, 8, 21, 10, 3, 8, 18, 3, 14, 6, 11, 7, 4, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [18, 18, 17, 24, 6, 18, 6, 6, 6, 24, 6, 6, 24, 6, 1, 24, 6, 6, 24, 24, 6, 24, 6, 6, 6, 6, 6, 6, 6, 6, 17, 17, 17, 17, 17, 17, 24, 17, 6, 24, 12, 6, 6, 6, 6, 6, 6, 6, 24, 24, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 18, 6, 6, 6, 26, 17, 13, 24, 6, 6, 18, 18, 17, 6, 6, 6, 6, 6, 17, 17, 24, 24, 17, 24, 15, 17, 17, 24, 24, 17, 6, 6, 6, 24, 17, 6, 17, 17, 18, 18, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 22, 17, 18, 6, 6, 6, 6, 6, 6, 6, 6, 6, 17, 17, 24, 17, 18, 18, 6, 6, 6, 17, 18, 6, 6, 6, 6, 6, 2, 24, 17, 17, 6, 6, 8, 6, 22, 28, 6, 26, 28, 6, 6, 6, 6, 18, 6, 24, 17, 6, 6, 17, 17, 24, 17, 6, 18, 17, 6, 6, 6, 17, 23, 6, 6, 24, 24, 6, 6, 17, 6, 6, 7, 6, 6, 24, 6, 24, 6, 23, 6, 24, 6, 6, 6, 17, 24, 6, 6, 6, 6, 17, 24, 18, 26, 17, 17, 17, 17, 17, 17, 24, 24, 6, 17, 24, 6, 24, 24, 6, 6, 6, 8, 17, 6, 6, 6, 6, 6, 24, 24, 24, 17, 17, 17, 18, 24, 6, 24, 6, 17, 6, 6, 6, 17, 17, 17, 17, 6, 6, 6, 28, 17, 2, 22, 24, 8, 24, 17, 24, 24, 24, 17, 6, 6, 6, 24, 6, 6, 17, 17, 6, 6, 6, 6, 6, 18, 26, 17, 17, 6, 17, 6, 6, 17, 6, 6, 6, 6, 6, 18, 22, 17, 17, 17, 17, 17, 17, 17, 17, 17, 6, 24, 17, 1, 17, 24, 17, 17, 6, 17, 24, 6, 17, 28, 17, 27, 17, 6, 27, 17, 17, 24, 18, 18, 18, 6, 18, 17, 18, 18, 17, 6, 24, 24, 17, 23, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 6, 6, 18, 6, 6, 18, 17, 6, 24, 24, 24, 24, 17, 6, 17, 6, 6, 6, 17, 17, 6, 6, 8, 17, 6, 26, 6, 24, 17, 24, 24, 24, 24, 17, 17, 17, 17, 6, 17, 17, 17, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 17, 26, 24, 24, 17, 17, 18, 18, 6, 6, 6, 6, 6, 18, 24, 6, 6, 17, 6, 8, 28, 6, 6, 22, 27, 17, 6, 17, 17, 6, 17, 17, 23, 17, 24, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 17, 17, 17, 17, 17, 6, 6, 6, 6, 6, 6, 6, 6, 24, 6, 6, 17, 24, 17, 6, 17, 17, 18, 18, 18, 17, 17, 17, 24, 17, 17, 6, 17, 17, 17, 17, 17, 6, 17, 17, 6, 6, 17, 6, 6, 24, 17, 17, 6, 17, 6]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 2 / 13]
Batch Loss: 7.9215
Batch Loss: 7.9215
Target: [3, 5, 12, 7, 9, 3, 11, 4, 24, 4, 13, 6, 5, 7, 8, 10, 3, 14, 4, 9, 5, 11, 8, 22, 4, 14, 3, 7, 10, 24, 4, 9, 5, 8, 11, 3, 15, 8, 10, 18, 7, 14, 4, 10, 15, 4, 3, 7, 10, 3, 5, 12, 4, 3, 5, 6, 22, 13, 8, 11, 3, 18, 8, 16, 10, 14, 6, 5, 7, 8, 10, 0, 0, 0, 0, 0] 
Predicted: [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 3 / 13]
Batch Loss: 7.9002
Model Summary: SpeechRecognitionModel(
  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (rescnn_layers): Sequential(
    (0): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fully_connected): Linear(in_features=1280, out_features=512, bias=True)
  (birnn_layers): Sequential(
    (0): BidirectionalGRU(
      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (2): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=512, out_features=29, bias=True)
  )
)
Model Parameters: 13858301
Features Shape: torch.Size([32, 501, 80])
Labels Shape: torch.Size([32, 75])
Features Length: tensor([501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501])
Shape: torch.Size([32])
Labels Length: tensor([75, 74, 45, 49, 59, 56, 45, 49, 62, 63, 61, 44, 57, 43, 58, 63, 38, 71,
        50, 64, 52, 50, 53, 54, 72, 74, 36, 63, 51, 58, 71, 72])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Model Summary: SpeechRecognitionModel(
  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (rescnn_layers): Sequential(
    (0): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fully_connected): Linear(in_features=1280, out_features=512, bias=True)
  (birnn_layers): Sequential(
    (0): BidirectionalGRU(
      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (2): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=512, out_features=29, bias=True)
  )
)
Model Parameters: 13858301
Features Shape: torch.Size([32, 501, 80])
Labels Shape: torch.Size([32, 91])
Features Length: tensor([501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501])
Shape: torch.Size([32])
Labels Length: tensor([65, 57, 57, 47, 42, 69, 47, 62, 70, 61, 45, 81, 63, 53, 53, 57, 80, 69,
        62, 58, 56, 43, 65, 58, 91, 46, 57, 52, 62, 66, 53, 42])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Model Summary: SpeechRecognitionModel(
  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (rescnn_layers): Sequential(
    (0): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fully_connected): Linear(in_features=1280, out_features=512, bias=True)
  (birnn_layers): Sequential(
    (0): BidirectionalGRU(
      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (2): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=512, out_features=29, bias=True)
  )
)
Model Parameters: 13858301
Features Shape: torch.Size([32, 501, 80])
Labels Shape: torch.Size([32, 81])
Features Length: tensor([501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501])
Shape: torch.Size([32])
Labels Length: tensor([68, 64, 41, 57, 57, 74, 41, 47, 39, 70, 51, 64, 79, 43, 48, 68, 47, 44,
        42, 72, 61, 57, 79, 62, 57, 53, 74, 63, 41, 68, 50, 81])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Batch Loss: 11.9902
Batch Loss: 11.9902
Target: [3, 20, 4, 8, 11, 20, 4, 3, 4, 27, 19, 13, 8, 11, 4, 9, 3, 5, 12, 4, 3, 15, 7, 5, 22, 3, 6, 10, 14, 3, 11, 4, 9, 15, 16, 4, 9, 3, 6, 3, 19, 6, 11, 6, 20, 13, 7, 14, 4, 11, 3, 8, 10, 3, 5, 12, 4, 3, 23, 6, 22, 3, 23, 11, 7, 14, 20, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [2, 2, 2, 10, 2, 2, 20, 2, 2, 1, 2, 2, 2, 24, 3, 2, 2, 3, 2, 16, 2, 2, 20, 2, 2, 3, 3, 3, 2, 2, 24, 24, 20, 24, 24, 3, 2, 2, 2, 11, 3, 2, 3, 24, 2, 2, 3, 2, 16, 24, 2, 2, 2, 2, 24, 24, 16, 2, 3, 3, 2, 2, 24, 2, 24, 3, 24, 3, 24, 3, 2, 2, 3, 2, 3, 24, 2, 2, 24, 24, 3, 24, 2, 3, 24, 24, 24, 3, 2, 2, 2, 2, 24, 2, 24, 24, 3, 2, 22, 2, 3, 2, 2, 3, 3, 2, 7, 3, 2, 2, 3, 2, 24, 24, 24, 2, 24, 2, 3, 2, 3, 3, 2, 20, 3, 24, 2, 2, 2, 2, 3, 2, 24, 2, 2, 2, 24, 24, 24, 24, 24, 2, 2, 2, 2, 2, 2, 3, 3, 3, 24, 24, 24, 24, 24, 2, 24, 24, 2, 3, 24, 24, 2, 24, 24, 19, 3, 24, 3, 2, 24, 2, 11, 3, 3, 11, 24, 2, 24, 2, 3, 24, 3, 20, 20, 3, 2, 24, 2, 16, 3, 2, 20, 2, 2, 12, 11, 2, 2, 24, 2, 3, 2, 20, 20, 2, 2, 3, 11, 2, 24, 24, 2, 2, 2, 4, 4, 2, 20, 2, 2, 20, 2, 20, 2, 2, 24, 11, 24, 2, 20, 3, 16, 2, 3, 2, 3, 2, 20, 20, 24, 3, 24, 2, 3, 20, 3, 23, 3, 20, 20]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 2 / 13]
Batch Loss: 11.2572
Batch Loss: 11.2572
Target: [3, 5, 12, 4, 3, 13, 6, 5, 5, 4, 11, 3, 11, 6, 15, 4, 3, 12, 6, 9, 3, 8, 15, 15, 16, 11, 11, 4, 14, 3, 6, 9, 3, 6, 3, 24, 6, 20, 11, 6, 10, 5, 3, 5, 8, 3, 20, 11, 4, 10, 6, 14, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [4, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 7, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 11, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 11, 3, 3, 11, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 24, 24, 3, 3, 11, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 11, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 24, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 11, 3, 3, 24, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 10, 11, 3, 11, 3, 3, 20, 2, 2, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 10, 2, 2, 3, 11, 3, 2, 11, 11, 3, 2, 3, 11]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 3 / 13]
Batch Loss: 7.3705
Batch Loss: 7.3705
Target: [3, 7, 5, 3, 21, 6, 9, 3, 10, 6, 17, 4, 14, 3, 21, 12, 7, 13, 4, 3, 9, 4, 6, 23, 8, 11, 20, 3, 21, 6, 9, 3, 9, 5, 7, 13, 13, 3, 6, 13, 7, 24, 4, 3, 21, 12, 7, 15, 12, 3, 19, 11, 8, 24, 4, 14, 3, 15, 8, 10, 5, 11, 8, 24, 4, 11, 9, 7, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 4 / 13]
Batch Loss: 3.7874
Batch Loss: 3.7874
Target: [3, 5, 12, 7, 9, 3, 13, 7, 9, 5, 3, 7, 9, 3, 7, 10, 3, 6, 13, 19, 12, 6, 23, 4, 5, 7, 15, 6, 13, 3, 8, 11, 14, 4, 11, 3, 23, 22, 3, 13, 6, 9, 5, 3, 10, 6, 17, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 5 / 13]
Batch Loss: 4.0748
Batch Loss: 4.0748
Target: [3, 6, 13, 6, 9, 3, 18, 8, 11, 3, 5, 12, 4, 3, 4, 18, 18, 4, 15, 5, 9, 3, 8, 18, 3, 23, 6, 14, 3, 5, 4, 6, 3, 6, 10, 14, 3, 23, 6, 14, 3, 5, 4, 17, 19, 4, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 6 / 13]
Batch Loss: 3.9797
Batch Loss: 3.9797
Target: [3, 5, 12, 7, 9, 3, 7, 9, 3, 9, 6, 7, 14, 3, 5, 8, 3, 12, 6, 24, 4, 3, 9, 5, 6, 11, 5, 4, 14, 3, 8, 18, 18, 3, 5, 12, 4, 3, 19, 11, 7, 10, 5, 3, 17, 4, 14, 7, 6, 3, 7, 10, 3, 10, 7, 20, 4, 11, 7, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 7 / 13]
Batch Loss: 3.3093
Batch Loss: 3.3093
Target: [3, 12, 4, 3, 17, 6, 14, 4, 3, 12, 7, 9, 3, 18, 7, 13, 17, 3, 14, 4, 23, 16, 5, 3, 18, 11, 8, 17, 3, 17, 8, 24, 7, 4, 3, 16, 17, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 8 / 13]
Batch Loss: 3.5014
Batch Loss: 3.5014
Target: [3, 7, 10, 3, 6, 18, 11, 7, 25, 6, 6, 10, 9, 3, 5, 12, 4, 3, 5, 8, 21, 10, 3, 7, 9, 3, 25, 10, 8, 21, 10, 3, 6, 9, 3, 23, 6, 11, 25, 13, 22, 21, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 9 / 13]
Batch Loss: 3.1728
Batch Loss: 3.1728
Target: [3, 15, 6, 5, 4, 9, 3, 18, 6, 15, 4, 14, 3, 10, 8, 3, 8, 19, 19, 8, 9, 7, 5, 7, 8, 10, 3, 18, 8, 11, 3, 12, 7, 9, 3, 23, 7, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 10 / 13]
Batch Loss: 3.2923
Batch Loss: 3.2923
Target: [3, 23, 16, 5, 3, 5, 12, 4, 3, 19, 12, 4, 10, 8, 17, 4, 10, 8, 10, 3, 12, 6, 9, 3, 23, 4, 4, 10, 3, 5, 11, 6, 15, 4, 14, 3, 23, 6, 15, 25, 3, 5, 8, 3, 23, 4, 18, 8, 11, 4, 3, 5, 12, 4, 3, 5, 4, 11, 17, 3, 21, 6, 9, 3, 15, 8, 7, 10, 4, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 11 / 13]
Batch Loss: 3.4454
Batch Loss: 3.4454
Target: [3, 12, 8, 21, 4, 24, 4, 11, 3, 7, 18, 3, 5, 12, 4, 3, 11, 6, 10, 20, 4, 11, 9, 3, 21, 8, 10, 3, 5, 12, 4, 3, 9, 4, 11, 7, 4, 9, 3, 22, 8, 16, 19, 19, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 12 / 13]
Model Summary: SpeechRecognitionModel(
  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (rescnn_layers): Sequential(
    (0): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)
  (birnn_layers): Sequential(
    (0): BidirectionalGRU(
      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (2): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (3): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (4): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=512, out_features=29, bias=True)
  )
)
Model Parameters: 23705373
Features Shape: torch.Size([32, 401, 128])
Labels Shape: torch.Size([32, 92])
Features Length: tensor([401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,
        401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,
        401, 401, 401, 401])
Shape: torch.Size([32])
Labels Length: tensor([86, 53, 50, 70, 62, 52, 67, 58, 71, 69, 92, 51, 82, 69, 68, 45, 59, 50,
        60, 57, 51, 33, 43, 59, 65, 47, 54, 73, 61, 63, 74, 71])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Batch Loss: 8.6419
Batch Loss: 8.6419
Target: [3, 6, 3, 20, 11, 4, 6, 5, 3, 18, 4, 9, 5, 7, 24, 6, 13, 3, 8, 18, 3, 20, 6, 5, 12, 4, 11, 7, 10, 20, 3, 18, 13, 8, 21, 4, 11, 9, 3, 21, 6, 9, 3, 15, 4, 13, 4, 23, 11, 6, 5, 4, 14, 3, 23, 22, 3, 19, 4, 13, 8, 19, 8, 10, 10, 4, 9, 7, 6, 10, 3, 21, 8, 17, 4, 10, 3, 7, 10, 3, 9, 19, 11, 7, 10, 20, 0, 0, 0, 0, 0, 0] 
Predicted: [12, 12, 10, 12, 11, 12, 12, 12, 28, 12, 12, 3, 12, 12, 10, 12, 12, 10, 12, 12, 12, 12, 12, 12, 10, 12, 12, 12, 10, 12, 12, 28, 10, 10, 10, 12, 3, 21, 10, 21, 12, 26, 12, 26, 12, 11, 12, 7, 21, 12, 12, 28, 12, 12, 12, 12, 10, 12, 21, 12, 10, 12, 12, 12, 10, 12, 12, 10, 12, 10, 12, 12, 12, 12, 12, 12, 10, 12, 12, 12, 12, 12, 11, 12, 11, 10, 12, 21, 7, 26, 12, 10, 12, 28, 12, 10, 12, 26, 10, 12, 10, 12, 10, 12, 12, 12, 12, 10, 26, 12, 10, 12, 12, 10, 12, 12, 12, 12, 12, 10, 10, 12, 10, 10, 10, 12, 10, 12, 12, 12, 12, 12, 21, 12, 12, 26, 10, 26, 10, 10, 12, 21, 12, 10, 10, 12, 21, 12, 12, 7, 12, 21, 12, 12, 7, 5, 12, 12, 12, 11, 3, 12, 12, 10, 7, 12, 12, 12, 12, 21, 21, 12, 15, 12, 12, 10, 12, 7, 10, 7, 7, 10, 12, 12, 12, 12, 12, 12, 12, 12, 21, 12, 12, 12, 12, 21, 21, 2, 12, 7, 10]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 2 / 13]
Batch Loss: 8.5952
Batch Loss: 8.5952
Target: [3, 5, 12, 4, 3, 19, 6, 7, 11, 3, 6, 13, 9, 8, 3, 8, 21, 10, 3, 6, 3, 10, 16, 17, 23, 4, 11, 3, 8, 18, 3, 11, 4, 9, 5, 6, 16, 11, 6, 10, 5, 9, 3, 7, 10, 3, 5, 12, 4, 3, 15, 7, 5, 22, 3, 8, 18, 3, 17, 7, 13, 6, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [21, 3, 0, 21, 10, 3, 4, 10, 21, 0, 3, 10, 12, 3, 21, 12, 12, 12, 0, 12, 12, 12, 12, 12, 12, 12, 0, 3, 7, 10, 7, 7, 10, 12, 12, 12, 10, 12, 3, 12, 12, 12, 10, 10, 12, 12, 3, 11, 3, 12, 10, 12, 5, 11, 10, 10, 12, 0, 21, 10, 12, 12, 12, 21, 12, 3, 0, 7, 12, 10, 0, 10, 12, 0, 0, 10, 10, 12, 21, 3, 12, 12, 3, 3, 3, 12, 21, 12, 12, 3, 10, 10, 0, 10, 12, 12, 12, 12, 10, 3, 3, 3, 12, 3, 21, 3, 7, 0, 3, 3, 12, 12, 12, 3, 12, 12, 12, 3, 12, 7, 12, 12, 0, 10, 7, 3, 0, 10, 12, 7, 10, 3, 10, 12, 0, 3, 12, 0, 10, 21, 12, 21, 21, 10, 10, 0, 10, 21, 3, 3, 12, 3, 7, 10, 3, 0, 0, 0, 12, 0, 21, 3, 7, 12, 3, 0, 0, 7, 0, 12, 10, 12, 12, 12, 10, 21, 12, 21, 12, 12, 12, 10, 12, 3, 5, 3, 3, 3, 21, 3, 3, 10, 3, 3, 10, 3, 3, 3, 3, 21, 12]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 3 / 13]
Batch Loss: 6.4756
Batch Loss: 6.4756
Target: [3, 7, 5, 3, 5, 8, 8, 25, 3, 19, 6, 11, 5, 3, 7, 10, 3, 5, 12, 4, 3, 14, 16, 10, 25, 7, 11, 25, 3, 4, 24, 6, 15, 16, 6, 5, 7, 8, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 4 / 13]
Batch Loss: 3.7939
Batch Loss: 3.7939
Target: [3, 17, 4, 10, 3, 6, 10, 14, 3, 23, 8, 22, 9, 3, 18, 16, 11, 10, 7, 9, 12, 4, 14, 3, 5, 12, 4, 17, 9, 4, 13, 24, 4, 9, 3, 21, 7, 5, 12, 3, 13, 7, 5, 5, 13, 4, 3, 23, 6, 20, 9, 3, 8, 11, 3, 10, 4, 5, 9, 3, 9, 5, 16, 18, 18, 4, 14, 3, 21, 7, 5, 12, 3, 19, 6, 19, 4, 11, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 5 / 13]
Batch Loss: 3.9408
Batch Loss: 3.9408
Target: [3, 6, 3, 9, 4, 15, 8, 10, 14, 3, 11, 4, 6, 9, 8, 10, 3, 7, 9, 3, 5, 8, 3, 20, 6, 7, 10, 3, 19, 8, 21, 4, 11, 9, 3, 6, 10, 14, 3, 7, 10, 18, 13, 16, 4, 10, 15, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 6 / 13]
Batch Loss: 3.9777
Batch Loss: 3.9777
Target: [3, 15, 6, 23, 13, 4, 3, 4, 10, 14, 9, 3, 16, 19, 3, 9, 12, 8, 8, 5, 7, 10, 20, 3, 12, 6, 17, 17, 4, 11, 3, 19, 6, 11, 6, 13, 22, 28, 7, 10, 20, 3, 12, 7, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 7 / 13]
Batch Loss: 4.9401
Batch Loss: 4.9401
Target: [3, 7, 10, 3, 5, 12, 8, 9, 4, 3, 14, 6, 22, 9, 3, 5, 12, 4, 3, 10, 6, 24, 22, 3, 14, 7, 14, 10, 5, 3, 12, 6, 24, 4, 3, 11, 6, 14, 6, 11, 3, 8, 19, 4, 11, 6, 5, 8, 11, 9, 3, 22, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 8 / 13]
Model Summary: SpeechRecognitionModel(
  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (rescnn_layers): Sequential(
    (0): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)
  (birnn_layers): Sequential(
    (0): BidirectionalGRU(
      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (2): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (3): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (4): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=512, out_features=29, bias=True)
  )
)
Model Parameters: 23705373
Features Shape: torch.Size([32, 401, 128])
Labels Shape: torch.Size([32, 92])
Features Length: tensor([401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,
        401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,
        401, 401, 401, 401])
Shape: torch.Size([32])
Labels Length: tensor([71, 69, 68, 56, 58, 64, 48, 48, 41, 50, 62, 62, 61, 58, 39, 55, 43, 72,
        81, 42, 92, 52, 58, 48, 59, 51, 79, 41, 52, 69, 45, 74])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Batch Loss: 9.0887
Batch Loss: 9.0887
Target: [3, 6, 5, 3, 5, 12, 4, 3, 6, 20, 4, 3, 8, 18, 3, 9, 7, 27, 5, 4, 4, 10, 3, 9, 12, 4, 3, 6, 11, 11, 7, 24, 4, 14, 3, 7, 10, 3, 17, 4, 27, 7, 15, 8, 3, 21, 12, 4, 11, 4, 3, 9, 12, 4, 3, 23, 4, 20, 6, 10, 3, 12, 4, 11, 3, 15, 6, 11, 4, 4, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [1, 20, 23, 23, 27, 23, 3, 1, 8, 23, 8, 8, 23, 18, 18, 23, 1, 23, 1, 8, 14, 8, 8, 27, 8, 23, 24, 23, 23, 27, 23, 23, 23, 23, 14, 23, 18, 8, 1, 23, 23, 8, 19, 23, 8, 23, 23, 23, 18, 1, 23, 23, 23, 8, 23, 23, 23, 8, 23, 1, 8, 23, 23, 23, 18, 23, 1, 23, 23, 8, 27, 24, 27, 18, 24, 8, 8, 1, 23, 1, 1, 23, 8, 1, 23, 1, 23, 27, 1, 27, 7, 23, 8, 23, 23, 8, 1, 24, 23, 23, 23, 8, 23, 23, 24, 24, 23, 23, 23, 23, 23, 1, 23, 1, 23, 23, 23, 1, 8, 23, 1, 23, 23, 1, 1, 18, 23, 23, 1, 1, 23, 18, 8, 23, 8, 23, 23, 18, 8, 18, 27, 27, 8, 18, 23, 1, 1, 24, 23, 23, 23, 8, 1, 23, 8, 20, 7, 1, 19, 23, 1, 1, 23, 1, 11, 20, 8, 20, 14, 14, 18, 23, 24, 27, 1, 14, 18, 18, 14, 1, 18, 27, 18, 23, 20, 20, 1, 27, 23, 27, 1, 7, 23, 27, 27, 20, 18, 7, 14, 15, 15]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 2 / 13]
Batch Loss: 9.0658
Batch Loss: 9.0658
Target: [3, 5, 12, 4, 3, 18, 7, 10, 9, 3, 21, 4, 11, 4, 3, 16, 9, 4, 14, 3, 5, 8, 3, 15, 8, 10, 5, 11, 8, 13, 3, 5, 12, 4, 3, 18, 13, 7, 20, 12, 5, 3, 19, 6, 5, 12, 3, 16, 9, 7, 10, 20, 3, 19, 7, 5, 15, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [1, 1, 23, 27, 27, 1, 8, 18, 8, 23, 18, 23, 1, 27, 8, 8, 23, 23, 22, 24, 23, 8, 23, 28, 7, 23, 23, 8, 23, 23, 1, 23, 14, 8, 23, 24, 8, 1, 27, 23, 1, 27, 23, 18, 18, 23, 23, 23, 23, 23, 23, 18, 3, 17, 12, 8, 8, 8, 18, 7, 8, 23, 23, 18, 1, 23, 23, 23, 23, 18, 23, 23, 23, 23, 24, 24, 8, 23, 14, 23, 8, 23, 8, 23, 27, 17, 18, 24, 23, 14, 8, 23, 8, 23, 8, 1, 18, 23, 8, 8, 23, 23, 18, 23, 23, 1, 1, 27, 23, 8, 23, 23, 8, 8, 23, 18, 23, 23, 23, 23, 23, 8, 1, 23, 23, 18, 23, 23, 1, 1, 23, 23, 18, 23, 8, 24, 14, 7, 12, 1, 18, 18, 1, 23, 1, 1, 20, 24, 23, 14, 1, 1, 1, 3, 1, 1, 18, 1, 1, 1, 1, 1, 24, 8, 12, 1, 1, 18, 23, 20, 1, 8, 18, 18, 1, 22, 27, 1, 1, 0, 1, 23, 1, 18, 24, 1, 1, 1, 1, 1, 1, 1, 8, 18, 18, 1, 27, 18, 18, 3, 1]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 3 / 13]
Batch Loss: 6.2770
Batch Loss: 6.2770
Target: [3, 23, 6, 11, 23, 8, 16, 11, 3, 6, 5, 5, 4, 10, 14, 4, 14, 3, 9, 15, 12, 8, 8, 13, 3, 16, 10, 5, 7, 13, 3, 9, 12, 4, 3, 21, 6, 9, 3, 18, 8, 16, 11, 5, 4, 4, 10, 3, 22, 4, 6, 11, 9, 3, 8, 13, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 4 / 13]
Batch Loss: 3.6248
Batch Loss: 3.6248
Target: [3, 5, 11, 4, 6, 5, 17, 4, 10, 5, 3, 15, 8, 10, 9, 7, 9, 5, 9, 3, 9, 7, 17, 19, 13, 22, 3, 8, 18, 3, 14, 7, 9, 15, 8, 10, 5, 7, 10, 16, 7, 10, 20, 3, 5, 12, 4, 3, 12, 6, 23, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 5 / 13]
Batch Loss: 4.2938
Batch Loss: 4.2938
Target: [3, 7, 5, 3, 21, 8, 10, 3, 5, 12, 4, 3, 7, 10, 14, 4, 19, 4, 10, 14, 4, 10, 5, 3, 9, 19, 7, 11, 7, 5, 3, 6, 21, 6, 11, 14, 3, 18, 8, 11, 3, 23, 4, 9, 5, 3, 14, 8, 15, 16, 17, 4, 10, 5, 6, 11, 22, 3, 18, 4, 6, 5, 16, 11, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 6 / 13]
Batch Loss: 6.2938
Batch Loss: 6.2938
Target: [3, 23, 4, 12, 7, 10, 14, 3, 5, 12, 7, 9, 3, 7, 9, 3, 5, 6, 7, 3, 17, 8, 3, 9, 12, 6, 10, 3, 5, 12, 4, 3, 5, 6, 13, 13, 4, 9, 5, 3, 12, 7, 13, 13, 3, 7, 10, 3, 12, 8, 10, 20, 3, 25, 8, 10, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 7 / 13]
Batch Loss: 8.1895
Batch Loss: 8.1895
Target: [3, 5, 12, 4, 3, 23, 8, 16, 13, 4, 24, 6, 11, 14, 3, 21, 7, 13, 13, 3, 23, 4, 10, 4, 18, 7, 5, 3, 18, 11, 8, 17, 3, 24, 4, 20, 4, 5, 6, 5, 7, 8, 10, 3, 8, 18, 3, 14, 7, 18, 18, 4, 11, 4, 10, 5, 3, 12, 4, 7, 20, 12, 5, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 8 / 13]
Batch Loss: 9.9331
Batch Loss: 9.9331
Target: [3, 5, 12, 4, 3, 18, 8, 11, 17, 4, 11, 3, 21, 6, 9, 3, 5, 12, 4, 3, 15, 6, 9, 4, 3, 21, 7, 5, 12, 3, 5, 12, 4, 3, 16, 10, 7, 5, 4, 14, 3, 9, 5, 6, 5, 4, 9, 3, 6, 10, 14, 3, 9, 21, 7, 5, 28, 4, 11, 13, 6, 10, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 9 / 13]
Batch Loss: 9.4356
Batch Loss: 9.4356
Target: [3, 5, 12, 4, 3, 15, 8, 13, 8, 11, 3, 6, 24, 8, 15, 6, 14, 8, 3, 7, 9, 3, 6, 3, 14, 6, 11, 25, 3, 22, 4, 13, 13, 8, 21, 20, 11, 4, 4, 10, 3, 15, 8, 13, 8, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 10 / 13]
Batch Loss: 8.6871
Batch Loss: 8.6871
Target: [3, 5, 12, 4, 3, 4, 13, 13, 4, 10, 3, 14, 4, 20, 4, 10, 4, 11, 4, 9, 3, 9, 12, 8, 21, 3, 12, 6, 14, 3, 6, 3, 21, 12, 6, 5, 9, 3, 21, 11, 8, 10, 20, 3, 21, 7, 5, 12, 3, 5, 12, 4, 9, 4, 3, 19, 12, 8, 5, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 11 / 13]
Model Summary: SpeechRecognitionModel(
  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (rescnn_layers): Sequential(
    (0): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)
  (birnn_layers): Sequential(
    (0): BidirectionalGRU(
      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (2): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (3): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (4): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=512, out_features=30, bias=True)
  )
)
Model Parameters: 23705886
Features Shape: torch.Size([32, 401, 128])
Labels Shape: torch.Size([32, 81])
Features Length: tensor([401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,
        401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,
        401, 401, 401, 401])
Shape: torch.Size([32])
Labels Length: tensor([71, 57, 41, 57, 80, 74, 51, 68, 61, 41, 67, 72, 58, 76, 81, 58, 75, 71,
        70, 59, 50, 74, 48, 62, 53, 73, 41, 54, 70, 36, 73, 66])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Batch Loss: 8.4963
Batch Loss: 8.4963
Target: [3, 8, 11, 7, 20, 7, 10, 6, 13, 13, 22, 3, 7, 5, 3, 21, 6, 9, 3, 13, 8, 15, 6, 5, 4, 14, 3, 21, 7, 5, 12, 7, 10, 3, 5, 12, 4, 3, 12, 7, 9, 5, 8, 11, 7, 15, 3, 23, 8, 16, 10, 14, 6, 11, 7, 4, 9, 3, 8, 18, 3, 13, 6, 10, 15, 6, 9, 12, 7, 11, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [14, 17, 18, 18, 18, 17, 18, 0, 18, 0, 18, 14, 27, 17, 18, 18, 18, 0, 17, 18, 14, 1, 1, 18, 14, 18, 18, 14, 14, 14, 14, 14, 14, 26, 14, 26, 14, 14, 18, 5, 5, 0, 5, 5, 0, 0, 14, 18, 18, 0, 14, 17, 18, 0, 27, 0, 0, 27, 14, 14, 18, 27, 18, 18, 14, 14, 14, 23, 17, 0, 0, 5, 5, 27, 14, 27, 17, 14, 17, 17, 17, 17, 18, 14, 0, 0, 0, 14, 14, 14, 14, 14, 0, 14, 14, 0, 0, 26, 14, 0, 26, 18, 17, 17, 14, 27, 5, 17, 14, 27, 14, 14, 27, 14, 14, 27, 27, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 17, 17, 14, 14, 14, 14, 14, 14, 14, 14, 17, 17, 14, 14, 14, 17, 14, 17, 14, 14, 17, 14, 14, 18, 18, 18, 18, 14, 18, 26, 18, 18, 14, 18, 18, 18, 14, 18, 14, 18, 14, 14, 15, 14, 5, 16, 18, 5, 18, 5, 14, 14, 14, 14, 18, 18, 18, 18, 18, 14, 18, 18, 14, 14, 18, 18, 14, 14, 14, 14, 14]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 2 / 13]
Model Summary: SpeechRecognitionModel(
  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (rescnn_layers): Sequential(
    (0): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)
  (birnn_layers): Sequential(
    (0): BidirectionalGRU(
      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (2): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (3): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (4): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=512, out_features=30, bias=True)
  )
)
Model Parameters: 23705886
Features Shape: torch.Size([32, 401, 128])
Labels Shape: torch.Size([32, 76])
Features Length: tensor([401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,
        401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,
        401, 401, 401, 401])
Shape: torch.Size([32])
Labels Length: tensor([69, 58, 27, 56, 65, 46, 69, 48, 50, 53, 51, 54, 43, 48, 44, 49, 74, 42,
        54, 48, 42, 70, 23, 57, 59, 71, 63, 72, 62, 76, 45, 59])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Batch Loss: 10.1992
Batch Loss: 10.1992
Target: [3, 5, 12, 4, 3, 17, 8, 10, 6, 9, 5, 4, 11, 22, 3, 15, 8, 10, 9, 7, 9, 5, 9, 3, 8, 18, 3, 5, 21, 8, 3, 15, 8, 16, 11, 5, 22, 6, 11, 14, 9, 3, 9, 16, 11, 11, 8, 16, 10, 14, 4, 14, 3, 23, 22, 3, 13, 8, 21, 3, 23, 16, 7, 13, 14, 7, 10, 20, 9, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [4, 7, 4, 7, 7, 7, 7, 7, 4, 7, 19, 4, 23, 7, 7, 7, 3, 7, 16, 16, 7, 7, 7, 1, 7, 7, 7, 7, 1, 7, 24, 1, 28, 4, 10, 25, 25, 4, 7, 4, 7, 7, 7, 10, 1, 4, 7, 7, 4, 7, 4, 4, 12, 7, 7, 7, 1, 7, 7, 4, 12, 23, 10, 4, 4, 7, 16, 1, 4, 13, 16, 18, 4, 1, 7, 4, 12, 4, 4, 12, 7, 20, 4, 7, 7, 4, 7, 7, 7, 4, 7, 7, 7, 4, 7, 4, 12, 4, 4, 4, 4, 4, 4, 7, 7, 18, 4, 24, 4, 4, 4, 4, 1, 7, 7, 1, 4, 7, 4, 1, 1, 6, 4, 4, 4, 4, 4, 4, 7, 4, 3, 4, 4, 4, 4, 7, 4, 4, 6, 7, 7, 7, 16, 7, 7, 4, 4, 7, 7, 4, 4, 16, 16, 16, 4, 4, 4, 4, 4, 19, 7, 7, 7, 7, 10, 4, 7, 4, 10, 10, 12, 4, 4, 4, 13, 10, 4, 4, 4, 16, 10, 4, 18, 18, 4, 18, 18, 4, 4, 18, 4, 1, 14, 13, 13, 12, 7, 18, 13, 6, 4]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 2 / 13]
Batch Loss: 8.9827
Batch Loss: 8.9827
Target: [3, 26, 8, 4, 3, 5, 4, 6, 17, 3, 6, 10, 14, 3, 5, 12, 4, 3, 19, 11, 8, 20, 11, 4, 9, 9, 3, 7, 9, 3, 12, 6, 13, 5, 4, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 7, 4, 0, 4, 0, 7, 4, 0, 0, 4, 4, 4, 4, 3, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 0, 4, 0, 4, 4, 0, 0, 4, 0, 0, 4, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 10, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 3 / 13]
Batch Loss: 5.4530
Batch Loss: 5.4530
Target: [3, 13, 6, 5, 4, 11, 3, 12, 4, 3, 21, 6, 9, 3, 4, 10, 20, 6, 20, 4, 14, 3, 8, 10, 3, 5, 12, 4, 3, 10, 4, 21, 3, 15, 12, 16, 11, 15, 12, 3, 8, 18, 3, 9, 6, 10, 5, 6, 3, 20, 7, 16, 9, 5, 7, 10, 6, 3, 7, 10, 3, 19, 6, 14, 16, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 4 / 13]
Batch Loss: 3.3859
Batch Loss: 3.3859
Target: [3, 5, 12, 4, 3, 25, 7, 5, 15, 12, 4, 10, 3, 21, 6, 9, 3, 4, 17, 19, 5, 22, 3, 6, 10, 14, 3, 9, 7, 13, 4, 10, 5, 3, 5, 12, 4, 3, 15, 13, 8, 15, 25, 3, 12, 6, 14, 3, 11, 16, 10, 3, 14, 8, 21, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 5 / 13]
Model Summary: SpeechRecognitionModel(
  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (rescnn_layers): Sequential(
    (0): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)
  (birnn_layers): Sequential(
    (0): BidirectionalGRU(
      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=512, out_features=30, bias=True)
  )
)
Model Parameters: 9506782
Features Shape: torch.Size([32, 501, 80])
Labels Shape: torch.Size([32, 83])
Features Length: tensor([501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501])
Shape: torch.Size([32])
Labels Length: tensor([49, 64, 42, 41, 74, 52, 56, 46, 70, 56, 62, 44, 76, 62, 51, 58, 83, 81,
        49, 51, 53, 72, 65, 42, 58, 53, 60, 53, 74, 71, 74, 61])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Model Summary: SpeechRecognitionModel(
  (cnn1): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (rescnn_layers): Sequential(
    (0): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): ResidualCNN(
      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout1): Dropout(p=0.1, inplace=False)
      (dropout2): Dropout(p=0.1, inplace=False)
      (layer_norm1): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm2): CNNLayerNorm(
        (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fully_connected): Linear(in_features=1280, out_features=512, bias=True)
  (birnn_layers): Sequential(
    (0): BidirectionalGRU(
      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (1): BidirectionalGRU(
      (BiGRU): GRU(1024, 512, batch_first=True, bidirectional=True)
      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (classifier): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=512, out_features=30, bias=True)
  )
)
Model Parameters: 9113374
Features Shape: torch.Size([32, 501, 80])
Labels Shape: torch.Size([32, 76])
Features Length: tensor([501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,
        501, 501, 501, 501])
Shape: torch.Size([32])
Labels Length: tensor([75, 63, 52, 65, 68, 71, 38, 54, 42, 53, 59, 68, 74, 67, 56, 57, 51, 56,
        68, 51, 67, 46, 41, 50, 44, 68, 57, 41, 76, 53, 62, 43])
Shape: torch.Size([32])
[Epoch 1] - [Batch 1 / 13]
Batch Loss: 11.9106
Batch Loss: 11.9106
Target: [3, 13, 16, 10, 14, 3, 6, 13, 9, 8, 3, 5, 16, 11, 10, 4, 14, 3, 14, 8, 21, 10, 3, 8, 18, 18, 4, 11, 9, 3, 18, 11, 8, 17, 3, 15, 13, 16, 23, 9, 3, 13, 7, 25, 4, 3, 11, 4, 6, 13, 3, 17, 6, 14, 11, 7, 14, 3, 6, 10, 14, 3, 23, 6, 22, 4, 11, 10, 3, 17, 16, 10, 7, 15, 12, 0] 
Predicted: [2, 5, 11, 11, 11, 11, 11, 11, 19, 11, 19, 19, 19, 11, 19, 2, 11, 11, 11, 20, 26, 2, 5, 7, 5, 20, 20, 20, 11, 11, 27, 21, 2, 20, 6, 14, 5, 19, 16, 11, 20, 2, 20, 20, 7, 7, 7, 11, 11, 11, 11, 11, 2, 11, 2, 20, 11, 11, 11, 11, 11, 11, 11, 2, 11, 11, 11, 11, 21, 11, 21, 18, 20, 11, 2, 20, 5, 19, 19, 2, 11, 11, 11, 27, 26, 11, 11, 19, 11, 29, 2, 2, 2, 2, 11, 11, 5, 5, 2, 2, 5, 5, 20, 23, 2, 7, 2, 19, 11, 29, 27, 2, 11, 26, 20, 12, 2, 6, 20, 11, 2, 11, 16, 11, 11, 5, 2, 26, 2, 20, 5, 7, 19, 7, 20, 19, 2, 19, 19, 2, 11, 2, 19, 11, 11, 11, 2, 2, 11, 5, 17, 5, 5, 14, 2, 19, 20, 11, 11, 19, 11, 11, 19, 19, 11, 2, 20, 2, 2, 2, 5, 2, 5, 2, 2, 16, 5, 20, 2, 21, 21, 21, 11, 16, 11, 2, 11, 11, 11, 11, 19, 2, 3, 2, 14, 19, 20, 20, 20, 2, 20, 5, 5, 19, 19, 19, 26, 11, 2, 2, 11, 11, 11, 11, 11, 11, 11, 20, 20, 11, 11, 11, 11, 20, 19, 11, 2, 11, 11, 11, 2, 20, 20, 11, 11, 11, 11, 11, 11, 11, 19, 19, 20, 20, 19, 19, 19, 20, 19, 19, 19]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 2 / 13]
Batch Loss: 10.2362
Batch Loss: 10.2362
Target: [3, 12, 4, 3, 21, 6, 9, 3, 6, 13, 9, 8, 3, 6, 3, 17, 4, 17, 23, 4, 11, 3, 8, 18, 3, 5, 12, 4, 3, 13, 6, 23, 8, 11, 3, 19, 6, 11, 5, 22, 9, 3, 10, 6, 5, 7, 8, 10, 6, 13, 3, 4, 27, 4, 15, 16, 5, 7, 24, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [11, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 11, 0, 0, 20, 0, 20, 0, 20, 0, 7, 7, 20, 11, 20, 20, 0, 0, 0, 6, 0, 19, 0, 11, 0, 0, 0, 11, 0, 0, 11, 0, 0, 0, 0, 0, 11, 11, 5, 0, 19, 5, 5, 16, 5, 14, 14, 0, 14, 0, 0, 0, 0, 11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 11, 11, 20, 0, 20, 5, 5, 11, 0, 0, 0, 21, 11, 11, 20, 5, 0, 0, 0, 0, 11, 11, 11, 11, 11, 0, 11, 0, 11, 11, 0, 0, 0, 0, 0, 0, 0, 11, 11, 11, 11, 0, 0, 0, 0, 0, 7, 5, 0, 26, 5, 5, 11, 0, 11, 0, 11, 11, 0, 0, 0, 11, 0, 0, 0, 0, 0, 14, 5, 5, 0, 2, 0, 0, 0, 16, 20, 0, 0, 0, 0, 0, 0, 19, 0, 0, 0, 0, 0, 11, 0, 0, 11, 0, 0, 0, 0, 11, 11, 11, 0, 11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 20, 5, 5, 0, 0, 5, 0, 11, 5, 5, 0, 5, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 3 / 13]
Batch Loss: 10.8260
Batch Loss: 10.8260
Target: [3, 20, 8, 24, 4, 11, 10, 17, 4, 10, 5, 3, 4, 14, 16, 15, 6, 5, 7, 8, 10, 3, 6, 10, 14, 3, 8, 18, 18, 7, 15, 7, 6, 13, 3, 23, 16, 9, 7, 10, 4, 9, 9, 3, 12, 8, 21, 4, 24, 4, 11, 3, 6, 11, 4, 3, 15, 6, 11, 11, 7, 4, 14, 3, 8, 16, 5, 3, 7, 10, 3, 17, 6, 10, 14, 6, 11, 7, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 4 / 13]
Batch Loss: 10.1772
Batch Loss: 10.1772
Target: [3, 7, 5, 3, 23, 4, 15, 6, 17, 4, 3, 25, 10, 8, 21, 10, 3, 6, 9, 3, 5, 12, 4, 3, 9, 12, 6, 19, 21, 7, 15, 25, 3, 12, 8, 6, 11, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 5 / 13]
Batch Loss: 10.0655
Batch Loss: 10.0655
Target: [3, 5, 12, 4, 3, 24, 4, 12, 7, 15, 13, 4, 9, 3, 13, 4, 10, 20, 5, 12, 3, 15, 6, 10, 3, 4, 27, 15, 4, 4, 14, 3, 9, 4, 24, 4, 10, 3, 17, 4, 5, 4, 11, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 6 / 13]
Batch Loss: 9.3055
Batch Loss: 9.3055
Target: [3, 7, 10, 3, 12, 7, 9, 3, 13, 6, 9, 5, 3, 22, 4, 6, 11, 9, 3, 23, 11, 8, 21, 10, 13, 4, 4, 3, 11, 4, 15, 4, 7, 24, 4, 14, 3, 6, 3, 10, 16, 17, 23, 4, 11, 3, 8, 18, 3, 12, 8, 10, 8, 16, 11, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 7 / 13]
Batch Loss: 8.2274
Batch Loss: 8.2274
Target: [3, 23, 16, 9, 7, 10, 4, 9, 9, 3, 7, 9, 3, 6, 3, 12, 7, 19, 3, 12, 8, 19, 3, 9, 8, 10, 20, 3, 8, 18, 3, 18, 8, 16, 11, 3, 17, 7, 10, 16, 5, 4, 9, 3, 6, 10, 14, 3, 4, 13, 4, 24, 4, 10, 3, 9, 4, 15, 8, 10, 14, 9, 3, 7, 10, 3, 13, 4, 10, 20, 5, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 8 / 13]
Batch Loss: 7.6871
Batch Loss: 7.6871
Target: [3, 5, 12, 4, 3, 9, 5, 6, 5, 16, 4, 3, 7, 9, 3, 9, 7, 5, 16, 6, 5, 4, 14, 3, 8, 16, 5, 9, 7, 14, 4, 3, 8, 18, 3, 21, 12, 4, 11, 4, 3, 12, 7, 9, 3, 8, 21, 10, 4, 11, 3, 13, 7, 24, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 9 / 13]
Batch Loss: 7.1389
Batch Loss: 7.1389
Target: [3, 17, 8, 9, 5, 3, 8, 18, 3, 5, 12, 4, 9, 4, 3, 9, 15, 12, 8, 8, 13, 9, 3, 15, 8, 10, 5, 7, 10, 16, 4, 3, 5, 8, 3, 4, 27, 7, 9, 5, 3, 5, 8, 14, 6, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 10 / 13]
Batch Loss: 6.6893
Batch Loss: 6.6893
Target: [3, 7, 5, 3, 10, 8, 21, 3, 12, 6, 9, 3, 7, 5, 9, 3, 8, 21, 10, 3, 21, 4, 23, 9, 7, 5, 4, 3, 21, 12, 4, 11, 4, 3, 6, 3, 9, 15, 6, 10, 10, 4, 14, 3, 15, 8, 19, 22, 3, 15, 6, 10, 3, 23, 4, 3, 18, 8, 16, 10, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 11 / 13]
Batch Loss: 5.6737
Batch Loss: 5.6737
Target: [3, 5, 12, 4, 3, 23, 4, 13, 3, 7, 9, 3, 9, 4, 13, 14, 8, 17, 3, 16, 9, 4, 14, 3, 6, 9, 3, 5, 12, 4, 3, 14, 4, 15, 7, 23, 4, 13, 3, 21, 6, 9, 3, 5, 12, 4, 3, 19, 11, 8, 19, 8, 9, 4, 14, 3, 21, 8, 11, 25, 7, 10, 20, 3, 16, 10, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 12 / 13]
Batch Loss: 5.0458
Batch Loss: 5.0458
Target: [3, 13, 6, 5, 4, 11, 3, 12, 4, 3, 21, 6, 9, 3, 4, 10, 20, 6, 20, 4, 14, 3, 8, 10, 3, 5, 12, 4, 3, 10, 4, 21, 3, 15, 12, 16, 11, 15, 12, 3, 8, 18, 3, 9, 6, 10, 5, 6, 3, 20, 7, 16, 9, 5, 7, 10, 6, 3, 7, 10, 3, 19, 6, 14, 16, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
[Epoch 1] - [Batch 13 / 13]
Batch Loss: 4.0377
Batch Loss: 4.0377
Target: [3, 8, 11, 7, 20, 7, 10, 6, 13, 13, 22, 3, 5, 12, 4, 3, 10, 6, 17, 4, 3, 21, 6, 9, 3, 5, 8, 3, 23, 4, 3, 14, 11, 16, 7, 14, 3, 23, 16, 5, 3, 5, 12, 7, 9, 3, 15, 12, 6, 10, 20, 4, 14, 3, 5, 8, 3, 14, 7, 6, 10, 6, 3, 14, 16, 11, 7, 10, 20, 3, 15, 8, 10, 9, 5, 11, 16, 15, 5, 7, 8, 10] 
Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
----------------------------------------------------------------------------------------------------
